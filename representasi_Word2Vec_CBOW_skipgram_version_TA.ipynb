{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqzju-QXuyIK",
        "outputId": "554f51d9-4d7b-4c7a-bf26-1caf5bac6010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim pandas openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRyvAs84vbvu"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyVyijvhu5S7",
        "outputId": "db674590-32c7-4762-cefa-de96c5989980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Download tokenizer (jika belum)\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JBm6IeNvX_-",
        "outputId": "a4d89dc1-3af1-4450-8cea-bbc71b72bb4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title  \\\n",
            "0  Efek Ekor Jas Pencalonan Anies, Elektabilitas ...   \n",
            "1  Ekonomi 2024 Ditargetkan Tumbuh 5,7 Persen, pa...   \n",
            "2  Survei Litbang Kompas: PDI-P, Gerindra, dan Go...   \n",
            "3  Survei Litbang \"Kompas\": Popularitas Golkar Te...   \n",
            "4  \"Endorsement\" dan Basa-basi Politik ala Jokowi...   \n",
            "\n",
            "                            Timestamp  \\\n",
            "0         21 Februari 2023, 15:30 WIB   \n",
            "1  Kompas.com - 21/02/2023, 14:22 WIB   \n",
            "2         21 Februari 2023, 09:58 WIB   \n",
            "3  Kompas.com - 21/02/2023, 05:23 WIB   \n",
            "4  Kompas.com - 21/02/2023, 05:20 WIB   \n",
            "\n",
            "                                            FullText  \\\n",
            "0  Hasil jajak pendapat yang diselenggarakan Litb...   \n",
            "1  JAKARTA, KOMPAS.com - Pemerintah menargetkan p...   \n",
            "2  PDI-Perjuangan, Partai Gerindra, dan Partai Go...   \n",
            "3  JAKARTA, KOMPAS.com - Survei Litbang Kompas Ja...   \n",
            "4   JAKARTA, KOMPAS.com - Presiden Joko Widodo la...   \n",
            "\n",
            "                                         CleanNarasi  \\\n",
            "0  Efek Ekor Jas Pencalonan Anies, Elektabilitas ...   \n",
            "1  Ekonomi 2024 Ditargetkan Tumbuh 5,7 Persen, pa...   \n",
            "2  Survei Litbang Kompas: PDI-P, Gerindra, dan Go...   \n",
            "3  Survei Litbang \"Kompas\": Popularitas Golkar Te...   \n",
            "4  \"Endorsement\" dan Basa-basi Politik ala Jokowi...   \n",
            "\n",
            "                                                 Url  label  sumber   scrap  \\\n",
            "0  https://video.kompas.com/watch/258152/efek-eko...    0.0  kompas  kompas   \n",
            "1  http://money.kompas.com/read/2023/02/21/142238...    0.0  kompas  kompas   \n",
            "2  https://video.kompas.com/watch/257988/survei-l...    0.0  kompas  kompas   \n",
            "3  http://nasional.kompas.com/read/2023/02/21/052...    0.0  kompas  kompas   \n",
            "4  http://nasional.kompas.com/read/2023/02/21/052...    0.0  kompas  kompas   \n",
            "\n",
            "                                       CleanedNarasi  count_exclamation  \\\n",
            "0  efek ekor jas pencalonan anies  elektabilitas ...                0.0   \n",
            "1  ekonomi      ditargetkan tumbuh     persen  pa...                0.0   \n",
            "2  survei litbang kompas  pdi p  gerindra  dan go...                0.0   \n",
            "3  survei litbang  kompas   popularitas golkar te...                0.0   \n",
            "4   endorsement  dan basa basi politik ala jokowi...                0.0   \n",
            "\n",
            "   count_question                                             tokens  \\\n",
            "0             0.0  ['efek', 'ekor', 'jas', 'pencalonan', 'anies',...   \n",
            "1             0.0  ['ekonomi', 'ditargetkan', 'tumbuh', 'persen',...   \n",
            "2             0.0  ['survei', 'litbang', 'kompas', 'pdi', 'p', 'g...   \n",
            "3             0.0  ['survei', 'litbang', 'kompas', 'popularitas',...   \n",
            "4             0.0  ['endorsement', 'dan', 'basa', 'basi', 'politi...   \n",
            "\n",
            "                                 tokens_no_stopwords  \\\n",
            "0  ['efek', 'ekor', 'jas', 'pencalonan', 'anies',...   \n",
            "1  ['ekonomi', 'ditargetkan', 'tumbuh', 'persen',...   \n",
            "2  ['survei', 'litbang', 'kompas', 'pdi', 'p', 'g...   \n",
            "3  ['survei', 'litbang', 'kompas', 'popularitas',...   \n",
            "4  ['endorsement', 'basa', 'basi', 'politik', 'al...   \n",
            "\n",
            "                                   normalized_tokens  capital_seq  \\\n",
            "0  ['efek', 'ekor', 'jas', 'pencalonan', 'anies',...          2.0   \n",
            "1  ['ekonomi', 'ditargetkan', 'tumbuh', 'persen',...          1.0   \n",
            "2  ['survei', 'litbang', 'kompas', 'pdi', 'p', 'g...         12.0   \n",
            "3  ['survei', 'litbang', 'kompas', 'popularitas',...         12.0   \n",
            "4  ['endorsement', 'basa', 'basi', 'politik', 'al...          0.0   \n",
            "\n",
            "   exclamation_seq  word_count  hyperbolic_count bahasa  \n",
            "0              0.0        89.0               0.0    NaN  \n",
            "1              0.0       311.0               0.0    NaN  \n",
            "2              0.0       115.0               0.0    NaN  \n",
            "3              0.0       247.0               0.0    NaN  \n",
            "4              0.0       179.0               0.0    NaN  \n"
          ]
        }
      ],
      "source": [
        "# Baca file Excel\n",
        "df = pd.read_excel('/content/combined_preprocessed.xlsx')  # Ganti dengan nama file kamu\n",
        "# Contoh melihat 5 baris pertama\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cek total NaN di kolom 'label'\n",
        "total_nan = df['label'].isna().sum()\n",
        "print(f\"\\nTotal NaN di kolom 'label': {total_nan}\")\n",
        "\n",
        "# 2. Lihat isi data (baris) yang memiliki NaN di kolom 'label'\n",
        "rows_with_nan = df[df['label'].isna()]\n",
        "print(\"\\nBaris dengan NaN di kolom 'label':\")\n",
        "print(rows_with_nan)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZdLveEMp1aR",
        "outputId": "5db3daf8-44af-434c-b3b1-8a75a90e38cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total NaN di kolom 'label': 21\n",
            "\n",
            "Baris dengan NaN di kolom 'label':\n",
            "     Title Timestamp FullText CleanNarasi  Url  label sumber scrap  \\\n",
            "2295   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "2418   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "3770   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "3962   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "3994   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4049   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4050   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4246   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4247   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4248   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4249   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4312   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4314   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4388   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4489   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4493   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4494   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4495   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4497   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4505   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "4507   NaN       NaN      NaN         NaN  NaN    NaN    NaN   NaN   \n",
            "\n",
            "     CleanedNarasi  count_exclamation  count_question tokens  \\\n",
            "2295           NaN                NaN             NaN    NaN   \n",
            "2418           NaN                NaN             NaN    NaN   \n",
            "3770           NaN                NaN             NaN    NaN   \n",
            "3962           NaN                NaN             NaN    NaN   \n",
            "3994           NaN                NaN             NaN    NaN   \n",
            "4049           NaN                NaN             NaN    NaN   \n",
            "4050           NaN                NaN             NaN    NaN   \n",
            "4246           NaN                NaN             NaN    NaN   \n",
            "4247           NaN                NaN             NaN    NaN   \n",
            "4248           NaN                NaN             NaN    NaN   \n",
            "4249           NaN                NaN             NaN    NaN   \n",
            "4312           NaN                NaN             NaN    NaN   \n",
            "4314           NaN                NaN             NaN    NaN   \n",
            "4388           NaN                NaN             NaN    NaN   \n",
            "4489           NaN                NaN             NaN    NaN   \n",
            "4493           NaN                NaN             NaN    NaN   \n",
            "4494           NaN                NaN             NaN    NaN   \n",
            "4495           NaN                NaN             NaN    NaN   \n",
            "4497           NaN                NaN             NaN    NaN   \n",
            "4505           NaN                NaN             NaN    NaN   \n",
            "4507           NaN                NaN             NaN    NaN   \n",
            "\n",
            "     tokens_no_stopwords normalized_tokens  capital_seq  exclamation_seq  \\\n",
            "2295                 NaN               NaN          NaN              NaN   \n",
            "2418                 NaN               NaN          NaN              NaN   \n",
            "3770                 NaN               NaN          NaN              NaN   \n",
            "3962                 NaN               NaN          NaN              NaN   \n",
            "3994                 NaN               NaN          NaN              NaN   \n",
            "4049                 NaN               NaN          NaN              NaN   \n",
            "4050                 NaN               NaN          NaN              NaN   \n",
            "4246                 NaN               NaN          NaN              NaN   \n",
            "4247                 NaN               NaN          NaN              NaN   \n",
            "4248                 NaN               NaN          NaN              NaN   \n",
            "4249                 NaN               NaN          NaN              NaN   \n",
            "4312                 NaN               NaN          NaN              NaN   \n",
            "4314                 NaN               NaN          NaN              NaN   \n",
            "4388                 NaN               NaN          NaN              NaN   \n",
            "4489                 NaN               NaN          NaN              NaN   \n",
            "4493                 NaN               NaN          NaN              NaN   \n",
            "4494                 NaN               NaN          NaN              NaN   \n",
            "4495                 NaN               NaN          NaN              NaN   \n",
            "4497                 NaN               NaN          NaN              NaN   \n",
            "4505                 NaN               NaN          NaN              NaN   \n",
            "4507                 NaN               NaN          NaN              NaN   \n",
            "\n",
            "      word_count  hyperbolic_count bahasa  \n",
            "2295         NaN               NaN    NaN  \n",
            "2418         NaN               NaN    NaN  \n",
            "3770         NaN               NaN    NaN  \n",
            "3962         NaN               NaN    NaN  \n",
            "3994         NaN               NaN    NaN  \n",
            "4049         NaN               NaN    NaN  \n",
            "4050         NaN               NaN    NaN  \n",
            "4246         NaN               NaN    NaN  \n",
            "4247         NaN               NaN    NaN  \n",
            "4248         NaN               NaN    NaN  \n",
            "4249         NaN               NaN    NaN  \n",
            "4312         NaN               NaN    NaN  \n",
            "4314         NaN               NaN    NaN  \n",
            "4388         NaN               NaN    NaN  \n",
            "4489         NaN               NaN    NaN  \n",
            "4493         NaN               NaN    NaN  \n",
            "4494         NaN               NaN    NaN  \n",
            "4495         NaN               NaN    NaN  \n",
            "4497         NaN               NaN    NaN  \n",
            "4505         NaN               NaN    NaN  \n",
            "4507         NaN               NaN    NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Hapus baris dengan NaN di kolom 'label'\n",
        "df_cleaned = df.dropna(subset=['label'])\n",
        "\n",
        "print(\"\\nDataFrame setelah menghapus baris dengan NaN di kolom 'label':\")\n",
        "print(df_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDWxWEARp5QM",
        "outputId": "2910fe43-3007-482a-b84b-0c70e98acc5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame setelah menghapus baris dengan NaN di kolom 'label':\n",
            "                                                   Title  \\\n",
            "0      Efek Ekor Jas Pencalonan Anies, Elektabilitas ...   \n",
            "1      Ekonomi 2024 Ditargetkan Tumbuh 5,7 Persen, pa...   \n",
            "2      Survei Litbang Kompas: PDI-P, Gerindra, dan Go...   \n",
            "3      Survei Litbang \"Kompas\": Popularitas Golkar Te...   \n",
            "4      \"Endorsement\" dan Basa-basi Politik ala Jokowi...   \n",
            "...                                                  ...   \n",
            "19029  (HOAX) Foto Raja Salman Mengangkat Tandu Jenaz...   \n",
            "19030  (HOAX) Jokowi dituduh bodoh, salah cara dalam ...   \n",
            "19031  (FITNAH) Jokowi dituduh memasukkan ribuan tena...   \n",
            "19032                   (HOAX) Mata Uang Rupiah Terpuruk   \n",
            "19033  (FITNAH) Ahok izinkan Natalan di Monas – tapi ...   \n",
            "\n",
            "                                Timestamp  \\\n",
            "0             21 Februari 2023, 15:30 WIB   \n",
            "1      Kompas.com - 21/02/2023, 14:22 WIB   \n",
            "2             21 Februari 2023, 09:58 WIB   \n",
            "3      Kompas.com - 21/02/2023, 05:23 WIB   \n",
            "4      Kompas.com - 21/02/2023, 05:20 WIB   \n",
            "...                                   ...   \n",
            "19029                 2015-09-15 00:00:00   \n",
            "19030                 2015-09-12 00:00:00   \n",
            "19031                 2015-09-08 00:00:00   \n",
            "19032                 2015-09-08 00:00:00   \n",
            "19033                       Juli 31, 2015   \n",
            "\n",
            "                                                FullText  \\\n",
            "0      Hasil jajak pendapat yang diselenggarakan Litb...   \n",
            "1      JAKARTA, KOMPAS.com - Pemerintah menargetkan p...   \n",
            "2      PDI-Perjuangan, Partai Gerindra, dan Partai Go...   \n",
            "3      JAKARTA, KOMPAS.com - Survei Litbang Kompas Ja...   \n",
            "4       JAKARTA, KOMPAS.com - Presiden Joko Widodo la...   \n",
            "...                                                  ...   \n",
            "19029  Sumber : media sosial\\nNarasi : Raja Salman da...   \n",
            "19030  Sumber : media sosial\\nNarasi : hehe, selalu b...   \n",
            "19031  Sumber : Media Sosial\\nNarasi : Pak Jokowi itu...   \n",
            "19032  Sumber : media sosial\\nNarasi : Hari ini, Rabu...   \n",
            "19033  SUMBER : Media Sosial\\nNARASI : MARI KITA TOLA...   \n",
            "\n",
            "                                             CleanNarasi  \\\n",
            "0      Efek Ekor Jas Pencalonan Anies, Elektabilitas ...   \n",
            "1      Ekonomi 2024 Ditargetkan Tumbuh 5,7 Persen, pa...   \n",
            "2      Survei Litbang Kompas: PDI-P, Gerindra, dan Go...   \n",
            "3      Survei Litbang \"Kompas\": Popularitas Golkar Te...   \n",
            "4      \"Endorsement\" dan Basa-basi Politik ala Jokowi...   \n",
            "...                                                  ...   \n",
            "19029  Raja Salman dari arab saudi membawa orang-oran...   \n",
            "19030  hehe, selalu bisa tersenyum melihat tingkah la...   \n",
            "19031  Pak Jokowi itu menjadi walikota periode pertam...   \n",
            "19032  Hari ini, Rabu (23/09/2015), nilai tukar rupia...   \n",
            "19033  MARI KITA TOLAK. 25 desember acara pastur di m...   \n",
            "\n",
            "                                                     Url  label        sumber  \\\n",
            "0      https://video.kompas.com/watch/258152/efek-eko...    0.0        kompas   \n",
            "1      http://money.kompas.com/read/2023/02/21/142238...    0.0        kompas   \n",
            "2      https://video.kompas.com/watch/257988/survei-l...    0.0        kompas   \n",
            "3      http://nasional.kompas.com/read/2023/02/21/052...    0.0        kompas   \n",
            "4      http://nasional.kompas.com/read/2023/02/21/052...    0.0        kompas   \n",
            "...                                                  ...    ...           ...   \n",
            "19029  https://turnbackhoax.id/2015/09/15/hoax-foto-r...    1.0  media sosial   \n",
            "19030  https://turnbackhoax.id/2015/09/12/jokowi-ditu...    1.0  media sosial   \n",
            "19031  https://turnbackhoax.id/2015/09/08/jokowi-ditu...    1.0  Media Sosial   \n",
            "19032  https://turnbackhoax.id/2015/09/08/mata-uang-r...    1.0  media sosial   \n",
            "19033  https://turnbackhoax.id/2015/07/31/fitnah-ahok...    1.0  Media Sosial   \n",
            "\n",
            "              scrap                                      CleanedNarasi  \\\n",
            "0            kompas  efek ekor jas pencalonan anies  elektabilitas ...   \n",
            "1            kompas  ekonomi      ditargetkan tumbuh     persen  pa...   \n",
            "2            kompas  survei litbang kompas  pdi p  gerindra  dan go...   \n",
            "3            kompas  survei litbang  kompas   popularitas golkar te...   \n",
            "4            kompas   endorsement  dan basa basi politik ala jokowi...   \n",
            "...             ...                                                ...   \n",
            "19029  turnbackhoax  raja salman dari arab saudi membawa orang oran...   \n",
            "19030  turnbackhoax  hehe  selalu bisa tersenyum melihat tingkah la...   \n",
            "19031  turnbackhoax  pak jokowi itu menjadi walikota periode pertam...   \n",
            "19032  turnbackhoax  hari ini  rabu   e o   ois   nilai tukar rupia...   \n",
            "19033  turnbackhoax  mari kita tolak   s desember acara pastur di m...   \n",
            "\n",
            "       count_exclamation  count_question  \\\n",
            "0                    0.0             0.0   \n",
            "1                    0.0             0.0   \n",
            "2                    0.0             0.0   \n",
            "3                    0.0             0.0   \n",
            "4                    0.0             0.0   \n",
            "...                  ...             ...   \n",
            "19029                0.0             0.0   \n",
            "19030                0.0             0.0   \n",
            "19031                0.0             2.0   \n",
            "19032                0.0             0.0   \n",
            "19033                6.0             3.0   \n",
            "\n",
            "                                                  tokens  \\\n",
            "0      ['efek', 'ekor', 'jas', 'pencalonan', 'anies',...   \n",
            "1      ['ekonomi', 'ditargetkan', 'tumbuh', 'persen',...   \n",
            "2      ['survei', 'litbang', 'kompas', 'pdi', 'p', 'g...   \n",
            "3      ['survei', 'litbang', 'kompas', 'popularitas',...   \n",
            "4      ['endorsement', 'dan', 'basa', 'basi', 'politi...   \n",
            "...                                                  ...   \n",
            "19029  ['raja', 'salman', 'dari', 'arab', 'saudi', 'm...   \n",
            "19030  ['hehe', 'selalu', 'bisa', 'tersenyum', 'melih...   \n",
            "19031  ['pak', 'jokowi', 'itu', 'menjadi', 'walikota'...   \n",
            "19032  ['hari', 'ini', 'rabu', 'e', 'o', 'ois', 'nila...   \n",
            "19033  ['mari', 'kita', 'tolak', 's', 'desember', 'ac...   \n",
            "\n",
            "                                     tokens_no_stopwords  \\\n",
            "0      ['efek', 'ekor', 'jas', 'pencalonan', 'anies',...   \n",
            "1      ['ekonomi', 'ditargetkan', 'tumbuh', 'persen',...   \n",
            "2      ['survei', 'litbang', 'kompas', 'pdi', 'p', 'g...   \n",
            "3      ['survei', 'litbang', 'kompas', 'popularitas',...   \n",
            "4      ['endorsement', 'basa', 'basi', 'politik', 'al...   \n",
            "...                                                  ...   \n",
            "19029  ['raja', 'salman', 'arab', 'saudi', 'membawa',...   \n",
            "19030  ['hehe', 'selalu', 'tersenyum', 'melihat', 'ti...   \n",
            "19031  ['pak', 'jokowi', 'menjadi', 'walikota', 'peri...   \n",
            "19032  ['hari', 'rabu', 'e', 'o', 'ois', 'nilai', 'tu...   \n",
            "19033  ['kita', 'tolak', 's', 'desember', 'acara', 'p...   \n",
            "\n",
            "                                       normalized_tokens  capital_seq  \\\n",
            "0      ['efek', 'ekor', 'jas', 'pencalonan', 'anies',...          2.0   \n",
            "1      ['ekonomi', 'ditargetkan', 'tumbuh', 'persen',...          1.0   \n",
            "2      ['survei', 'litbang', 'kompas', 'pdi', 'p', 'g...         12.0   \n",
            "3      ['survei', 'litbang', 'kompas', 'popularitas',...         12.0   \n",
            "4      ['endorsement', 'basa', 'basi', 'politik', 'al...          0.0   \n",
            "...                                                  ...          ...   \n",
            "19029  ['raja', 'salman', 'dari', 'arab', 'saudi', 'm...          0.0   \n",
            "19030  ['hehe', 'selalu', 'bisa', 'tersenyum', 'melih...          0.0   \n",
            "19031  ['pak', 'jokowi', 'itu', 'menjadi', 'walikota'...          5.0   \n",
            "19032  ['hari', 'ini', 'rabu', 'e', 'o', 'ois', 'nila...          1.0   \n",
            "19033  ['mari', 'kita', 'tolak', 's', 'desember', 'ac...          9.0   \n",
            "\n",
            "       exclamation_seq  word_count  hyperbolic_count bahasa  \n",
            "0                  0.0        89.0               0.0    NaN  \n",
            "1                  0.0       311.0               0.0    NaN  \n",
            "2                  0.0       115.0               0.0    NaN  \n",
            "3                  0.0       247.0               0.0    NaN  \n",
            "4                  0.0       179.0               0.0    NaN  \n",
            "...                ...         ...               ...    ...  \n",
            "19029              0.0        24.0               0.0     id  \n",
            "19030              0.0        19.0               0.0     id  \n",
            "19031              0.0        98.0               0.0     id  \n",
            "19032              0.0        16.0               0.0     id  \n",
            "19033              1.0        49.0               0.0     id  \n",
            "\n",
            "[19013 rows x 19 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNxk9LRPvwyD",
        "outputId": "2fbd7ca8-7e85-4e0b-b0b5-3c8de4d8e18d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Melatih model CBOW...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melatih model Skip-gram...\n"
          ]
        }
      ],
      "source": [
        "# Latih model Word2Vec CBOW dan Skip-gram\n",
        "print(\"\\nMelatih model CBOW...\")\n",
        "model_cbow = Word2Vec(\n",
        "    sentences=df_cleaned['tokens_no_stopwords'],\n",
        "    vector_size=100,  # Ukuran vektor\n",
        "    window=5,         # Jumlah kata di sekitar\n",
        "    min_count=1,      # Frekuensi minimum kata\n",
        "    workers=4,        # Jumlah thread\n",
        "    sg=0              # 0: CBOW\n",
        ")\n",
        "\n",
        "print(\"Melatih model Skip-gram...\")\n",
        "model_sg = Word2Vec(\n",
        "    sentences=df_cleaned['tokens_no_stopwords'],\n",
        "    vector_size=100,  # Ukuran vektor harus sama untuk penggabungan\n",
        "    window=5,         # Jumlah kata di sekitar\n",
        "    min_count=1,      # Frekuensi minimum kata\n",
        "    workers=4,        # Jumlah thread\n",
        "    sg=1              # 1: Skip-gram\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmwqieljv7PG"
      },
      "outputs": [],
      "source": [
        "# Simpan model (opsional)\n",
        "model_cbow.save(\"word2vec_model_cbow.model\")\n",
        "model_sg.save(\"word2vec_model_sg.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF5OHR5iwYTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01caade6-dd67-4b35-a914-44c3c6bd8fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Menghitung vektor kalimat...\n"
          ]
        }
      ],
      "source": [
        "# Fungsi untuk mendapatkan vektor rata-rata dari sebuah kalimat untuk model tertentu\n",
        "def get_sentence_vector(tokens, model):\n",
        "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
        "    if not vectors:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "# --- Bagian Baru: Dapatkan vektor dari CBOW, Skip-gram, dan Gabungan ---\n",
        "print(\"\\nMenghitung vektor kalimat...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np1VE_Wrwb6x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95a0958-7838-4c88-b8b1-6d29a69fc77d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4102254164.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['vector_cbow'] = df_cleaned['tokens_no_stopwords'].apply(lambda x: get_sentence_vector(x, model_cbow))\n",
            "/tmp/ipython-input-4102254164.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['vector_sg'] = df_cleaned['tokens_no_stopwords'].apply(lambda x: get_sentence_vector(x, model_sg))\n",
            "/tmp/ipython-input-4102254164.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['vector_combined'] = df_cleaned.apply(\n"
          ]
        }
      ],
      "source": [
        "# Vektor CBOW\n",
        "df_cleaned['vector_cbow'] = df_cleaned['tokens_no_stopwords'].apply(lambda x: get_sentence_vector(x, model_cbow))\n",
        "\n",
        "# Vektor Skip-gram\n",
        "df_cleaned['vector_sg'] = df_cleaned['tokens_no_stopwords'].apply(lambda x: get_sentence_vector(x, model_sg))\n",
        "\n",
        "# Vektor Gabungan (rata-rata dari CBOW dan Skip-gram)\n",
        "df_cleaned['vector_combined'] = df_cleaned.apply(\n",
        "    lambda row: (np.array(row['vector_cbow']) + np.array(row['vector_sg'])) / 2.0,\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhngd3cWweTN",
        "outputId": "0183552a-fd2b-4e6d-959a-7fe591d6420b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hasil vektor untuk beberapa baris:\n",
            "                                       CleanedNarasi  \\\n",
            "0  efek ekor jas pencalonan anies  elektabilitas ...   \n",
            "1  ekonomi      ditargetkan tumbuh     persen  pa...   \n",
            "2  survei litbang kompas  pdi p  gerindra  dan go...   \n",
            "3  survei litbang  kompas   popularitas golkar te...   \n",
            "4   endorsement  dan basa basi politik ala jokowi...   \n",
            "\n",
            "                                         vector_cbow  \\\n",
            "0  [0.1068104, 0.16480927, -0.06170332, 0.4143358...   \n",
            "1  [0.10346157, 0.15733077, -0.07548306, 0.380306...   \n",
            "2  [0.101267934, 0.16018696, -0.06279436, 0.34137...   \n",
            "3  [0.090119496, 0.16516396, -0.058607463, 0.3756...   \n",
            "4  [0.09179839, 0.15346093, -0.053987127, 0.39101...   \n",
            "\n",
            "                                           vector_sg  \\\n",
            "0  [0.028260801, -0.06512354, -0.109418556, 0.042...   \n",
            "1  [0.032424506, -0.06527497, -0.10640011, 0.0455...   \n",
            "2  [0.029482245, -0.0674338, -0.10877135, 0.04778...   \n",
            "3  [0.028165009, -0.06870859, -0.10876783, 0.0469...   \n",
            "4  [0.027634883, -0.06551115, -0.11037686, 0.0447...   \n",
            "\n",
            "                                     vector_combined  \n",
            "0  [0.0675356, 0.049842864, -0.08556094, 0.228501...  \n",
            "1  [0.06794304, 0.0460279, -0.090941586, 0.212921...  \n",
            "2  [0.06537509, 0.046376582, -0.085782856, 0.1945...  \n",
            "3  [0.059142254, 0.048227686, -0.08368765, 0.2113...  \n",
            "4  [0.059716634, 0.04397489, -0.08218199, 0.21787...  \n"
          ]
        }
      ],
      "source": [
        "# Lihat hasil\n",
        "print(\"\\nHasil vektor untuk beberapa baris:\")\n",
        "print(df_cleaned[['CleanedNarasi', 'vector_cbow', 'vector_sg', 'vector_combined']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3urBsFzyp-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8d292c-cbba-4f1c-831c-3e1f1d24483d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-679521417.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['vector_combined_str'] = df_cleaned['vector_combined'].apply(lambda x: ','.join(map(str, x)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame dengan vektor CBOW, Skip-gram, dan Gabungan telah disimpan.\n"
          ]
        }
      ],
      "source": [
        "# Simpan DataFrame ke pickle\n",
        "df_cleaned.to_pickle('combined_with_vectors_cbow_sg.pkl')\n",
        "\n",
        "# Konversi vektor gabungan ke string untuk disimpan ke Excel\n",
        "df_cleaned['vector_combined_str'] = df_cleaned['vector_combined'].apply(lambda x: ','.join(map(str, x)))\n",
        "\n",
        "# Simpan DataFrame ke Excel (vektor gabungan dalam bentuk string)\n",
        "df_cleaned.to_excel('combined_with_vectors_cbow_sg.xlsx', index=False)\n",
        "\n",
        "print(\"\\nDataFrame dengan vektor CBOW, Skip-gram, dan Gabungan telah disimpan.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}